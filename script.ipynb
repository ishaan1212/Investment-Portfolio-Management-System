{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\python312\\lib\\site-packages (0.2.52)\n",
      "Requirement already satisfied: mysql-connector-python in c:\\python312\\lib\\site-packages (9.2.0)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\python312\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (3.10.0)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: hubspot-api-client in c:\\python312\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\python312\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\python312\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\python312\\lib\\site-packages (from yfinance) (5.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\gurpreet singh\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\python312\\lib\\site-packages (from yfinance) (2024.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\python312\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\python312\\lib\\site-packages (from yfinance) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\python312\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\python312\\lib\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gurpreet singh\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gurpreet singh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: urllib3<3.0,>=1.15 in c:\\python312\\lib\\site-packages (from hubspot-api-client) (2.2.2)\n",
      "Requirement already satisfied: six<2.0,>=1.10 in c:\\users\\gurpreet singh\\appdata\\roaming\\python\\python312\\site-packages (from hubspot-api-client) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2023.1.1 in c:\\python312\\lib\\site-packages (from hubspot-api-client) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: webencodings in c:\\python312\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance mysql-connector-python pandas numpy scipy matplotlib seaborn hubspot-api-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from hubspot import HubSpot\n",
    "from hubspot.crm.contacts import SimplePublicObjectInput\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MySQL Connection Successful & Table Created!\n"
     ]
    }
   ],
   "source": [
    "#   Connect to MySQL Database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"pass\",  \n",
    "    database=\"db_name\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#  Create Table (If Not Exists)\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS stock_prices (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        stock_symbol VARCHAR(10),\n",
    "        date DATE,\n",
    "        close_price FLOAT\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\" MySQL Connection Successful & Table Created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting datta from Yahoo Finance API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# List of stocks to fetch (You can add more)\n",
    "stock_symbols = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\"]\n",
    "\n",
    "# Connect to MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    port=3306,          \n",
    "    user=\"root\",\n",
    "    password=\"pass\",  \n",
    "    database=\"db_name\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Loop through each stock symbol\n",
    "for stock_symbol in stock_symbols:\n",
    "    print(f\"Fetching data for {stock_symbol}...\")\n",
    "\n",
    "    # Fetch historical stock data (last 5 years)\n",
    "    stock = yf.Ticker(stock_symbol)\n",
    "    data = stock.history(period=\"5y\")\n",
    "\n",
    "    # Reset index to get 'Date' as a column\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Insert data into MySQL\n",
    "    for index, row in data.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO stock_prices (date, stock_symbol, open_price, high_price, low_price, close_price, volume)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", (row['Date'], stock_symbol, row['Open'], row['High'], row['Low'], row['Close'], row['Volume']))\n",
    "    \n",
    "    print(f\" Inserted {len(data)} rows for {stock_symbol} into MySQL!\")\n",
    "\n",
    "# Commit changes\n",
    "conn.commit()\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"🎉 All stock data inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fetch the same stocks from MySQL and process their historical returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"pass\",\n",
    "    database=\"db_name\"\n",
    ")\n",
    "\n",
    "# Fetch stock data\n",
    "query = \"SELECT stock_symbol, date, close_price FROM stock_prices ORDER BY date;\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close MySQL connection\n",
    "conn.close()\n",
    "\n",
    "# Pivot data for easier processing\n",
    "df = df.pivot(index='date', columns='stock_symbol', values='close_price')\n",
    "\n",
    "# Calculate daily returns\n",
    "returns = df.pct_change().dropna()\n",
    "\n",
    "# Display sample data\n",
    "returns.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll generate 10,000 random portfolios and calculate expected return, risk (volatility), and Sharpe Ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of portfolios to simulate\n",
    "num_portfolios = 10000\n",
    "\n",
    "# Store portfolio metrics\n",
    "all_weights = np.zeros((num_portfolios, len(df.columns)))\n",
    "ret_arr = np.zeros(num_portfolios)\n",
    "vol_arr = np.zeros(num_portfolios)\n",
    "sharpe_arr = np.zeros(num_portfolios)\n",
    "\n",
    "# Get average annual returns and covariance matrix\n",
    "annual_returns = returns.mean() * 252\n",
    "cov_matrix = returns.cov() * 252\n",
    "\n",
    "# Monte Carlo Simulation\n",
    "for i in range(num_portfolios):\n",
    "    # Random weights for each stock\n",
    "    weights = np.random.random(len(df.columns))\n",
    "    weights /= np.sum(weights)  # Normalize to sum to 1\n",
    "    \n",
    "    # Expected return\n",
    "    ret_arr[i] = np.sum(weights * annual_returns)\n",
    "    \n",
    "    # Expected volatility\n",
    "    vol_arr[i] = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    \n",
    "    # Sharpe Ratio\n",
    "    sharpe_arr[i] = ret_arr[i] / vol_arr[i]\n",
    "    \n",
    "    # Store weights\n",
    "    all_weights[i, :] = weights\n",
    "\n",
    "# Convert results to DataFrame\n",
    "portfolio_df = pd.DataFrame({\n",
    "    'Return': ret_arr,\n",
    "    'Volatility': vol_arr,\n",
    "    'Sharpe Ratio': sharpe_arr\n",
    "})\n",
    "\n",
    "# Display top portfolios\n",
    "portfolio_df.sort_values(by=\"Sharpe Ratio\", ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the portfolio with the highest Sharpe Ratio\n",
    "max_sharpe_idx = sharpe_arr.argmax()\n",
    "optimal_weights = all_weights[max_sharpe_idx]\n",
    "\n",
    "# Display optimal weights\n",
    "optimal_portfolio = pd.DataFrame({\n",
    "    'Stock': df.columns,\n",
    "    'Optimal Weight': optimal_weights\n",
    "})\n",
    "\n",
    "optimal_portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(vol_arr, ret_arr, c=sharpe_arr, cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "\n",
    "# Highlight the optimal portfolio\n",
    "plt.scatter(vol_arr[max_sharpe_idx], ret_arr[max_sharpe_idx], c='red', marker='*', s=200, label='Optimal Portfolio')\n",
    "\n",
    "plt.xlabel('Volatility (Risk)')\n",
    "plt.ylabel('Expected Return')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df.pct_change().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas matplotlib scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m num_portfolios \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Store portfolio metrics\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m all_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_portfolios, \u001b[38;5;28mlen\u001b[39m(\u001b[43mreturns\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)))\n\u001b[0;32m      8\u001b[0m ret_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_portfolios)\n\u001b[0;32m      9\u001b[0m vol_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_portfolios)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'returns' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Number of simulated portfolios\n",
    "num_portfolios = 10000\n",
    "\n",
    "# Store portfolio metrics\n",
    "all_weights = np.zeros((num_portfolios, len(returns.columns)))\n",
    "ret_arr = np.zeros(num_portfolios)\n",
    "vol_arr = np.zeros(num_portfolios)\n",
    "sharpe_arr = np.zeros(num_portfolios)\n",
    "\n",
    "# Annualized statistics\n",
    "annual_returns = returns.mean() * 252  # Annualizing daily returns\n",
    "cov_matrix = returns.cov() * 252  # Annualized covariance matrix\n",
    "\n",
    "# Monte Carlo Simulation\n",
    "for i in range(num_portfolios):\n",
    "    # Generate random weights for each stock\n",
    "    weights = np.random.random(len(returns.columns))\n",
    "    weights /= np.sum(weights)  # Normalize so they sum to 1\n",
    "\n",
    "    # Portfolio Return\n",
    "    ret_arr[i] = np.sum(weights * annual_returns)\n",
    "\n",
    "    # Portfolio Volatility (Risk)\n",
    "    vol_arr[i] = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "\n",
    "    # Sharpe Ratio (Using risk-free rate = 3.2%)\n",
    "    sharpe_arr[i] = (ret_arr[i] - 0.032) / vol_arr[i]  \n",
    "\n",
    "    # Store weights\n",
    "    all_weights[i, :] = weights\n",
    "\n",
    "# Convert results to DataFrame\n",
    "portfolio_df = pd.DataFrame({\n",
    "    'Return': ret_arr,\n",
    "    'Volatility': vol_arr,\n",
    "    'Sharpe Ratio': sharpe_arr\n",
    "})\n",
    "\n",
    "# Display the top 5 portfolios with the highest Sharpe Ratios\n",
    "portfolio_df.sort_values(by=\"Sharpe Ratio\", ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index of portfolio with highest Sharpe Ratio\n",
    "max_sharpe_idx = sharpe_arr.argmax()\n",
    "optimal_weights = all_weights[max_sharpe_idx]\n",
    "\n",
    "# Display optimal weights\n",
    "optimal_portfolio = pd.DataFrame({\n",
    "    'Stock': returns.columns,\n",
    "    'Optimal Weight': optimal_weights\n",
    "})\n",
    "\n",
    "# Display the optimal stock allocation\n",
    "print(\" Optimal Portfolio Allocation:\")\n",
    "optimal_portfolio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Efficient Frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(vol_arr, ret_arr, c=sharpe_arr, cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "\n",
    "# Highlight the optimal portfolio\n",
    "plt.scatter(vol_arr[max_sharpe_idx], ret_arr[max_sharpe_idx], c='red', marker='*', s=200, label='Optimal Portfolio')\n",
    "\n",
    "plt.xlabel('Volatility (Risk)')\n",
    "plt.ylabel('Expected Return')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stock returns over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot daily returns for each stock\n",
    "for stock in returns.columns:\n",
    "    plt.plot(returns.index, returns[stock], label=stock, alpha=0.8)\n",
    "\n",
    "# Formatting\n",
    "plt.title(\"Stock Daily Returns Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Daily Return (%)\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulatiive returns plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cumulative returns\n",
    "cumulative_returns = (1 + returns).cumprod()\n",
    "\n",
    "# Plot cumulative returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "for stock in cumulative_returns.columns:\n",
    "    plt.plot(cumulative_returns.index, cumulative_returns[stock], label=stock, alpha=0.8)\n",
    "\n",
    "# Formatting\n",
    "plt.title(\"Cumulative Returns Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stock allocation according to best portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the best portfolio (highest Sharpe Ratio)\n",
    "max_sharpe_idx = sharpe_arr.argmax()\n",
    "\n",
    "# Extract the optimal stock weights\n",
    "optimal_weights = all_weights[max_sharpe_idx]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "optimal_portfolio = pd.DataFrame({\n",
    "    'Stock': returns.columns,\n",
    "    'Optimal Weight': optimal_weights\n",
    "})\n",
    "\n",
    "# Display the best portfolio allocation\n",
    "print(\" Optimal Portfolio Allocation:\")\n",
    "optimal_portfolio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing best portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Optimal Portfolio Allocation\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(optimal_portfolio[\"Optimal Weight\"], labels=optimal_portfolio[\"Stock\"], autopct='%1.1f%%', startangle=140)\n",
    "plt.title(\"Optimal Portfolio Allocation (Best Sharpe Ratio)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up CRM system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hubspot-api-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hubspot\n",
    "print(\"HubSpot API Client is installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your actual HubSpot OAuth Token\n",
    "HUBSPOT_ACCESS_TOKEN = \"your_oauth_access_token_here\"\n",
    "\n",
    "# HubSpot API URL for creating a contact\n",
    "HUBSPOT_API_URL = \"https://api.hubapi.com/crm/v3/objects/contacts\"\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {HUBSPOT_ACCESS_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Contact data (test user)\n",
    "contact_data = {\n",
    "    \"properties\": {\n",
    "        \"email\": \"testuser@example.com\",\n",
    "        \"firstname\": \"Test\",\n",
    "        \"lastname\": \"User\",\n",
    "        \"investment_status\": \"High Risk\",\n",
    "        \"portfolio_allocation\": \"{'AAPL': 30%, 'TSLA': 20%, 'GOOGL': 25%, 'AMZN': 25%}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(HUBSPOT_API_URL, headers=headers, json=contact_data)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 201:\n",
    "    print(\" Contact successfully added to HubSpot!\")\n",
    "else:\n",
    "    print(f\"❌ Error: {response.status_code}, {response.json()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding investment data in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#  Connect to MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"pass\",  \n",
    "    database=\"db_name\"\n",
    ")\n",
    "\n",
    "query = \"SELECT stock_symbol, date, close_price FROM stock_prices;\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "#  Compute Daily Returns\n",
    "df['daily_return'] = df.groupby('stock_symbol')['close_price'].pct_change()\n",
    "\n",
    "#  Compute Annualized Volatility (Assuming 252 trading days)\n",
    "volatility = df.groupby('stock_symbol')['daily_return'].std() * np.sqrt(252)\n",
    "\n",
    "#  Define Investment Risk Levels\n",
    "def classify_risk(vol):\n",
    "    if vol > 0.40:\n",
    "        return \"High Risk\"\n",
    "    elif 0.20 <= vol <= 0.40:\n",
    "        return \"Moderate Risk\"\n",
    "    else:\n",
    "        return \"Low Risk\"\n",
    "\n",
    "#  Apply Classification\n",
    "investment_status = volatility.apply(classify_risk).reset_index()\n",
    "investment_status.columns = ['stock_symbol', 'investment_status']\n",
    "\n",
    "#  Merge with Main Data\n",
    "df = df.merge(investment_status, on='stock_symbol', how='left')\n",
    "\n",
    "#  Save Back to SQL\n",
    "cursor = conn.cursor()\n",
    "for index, row in df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        UPDATE stock_prices \n",
    "        SET investment_status = %s \n",
    "        WHERE stock_symbol = %s;\n",
    "    \"\"\", (row['investment_status'], row['stock_symbol']))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\" Investment Status Updated in SQL!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"pass\",  \n",
    "    database=\"db_name\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch stock data\n",
    "query = \"SELECT stock_symbol, date, close_price FROM stock_prices\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Calculate Daily Returns\n",
    "df['daily_return'] = df.groupby('stock_symbol')['close_price'].pct_change()\n",
    "\n",
    "# Calculate Annualized Return and Volatility\n",
    "annual_returns = df.groupby('stock_symbol')['daily_return'].mean() * 252\n",
    "annual_volatility = df.groupby('stock_symbol')['daily_return'].std() * (252 ** 0.5)\n",
    "\n",
    "# Assume a risk-free rate of 3.20%\n",
    "risk_free_rate = 0.032\n",
    "sharpe_ratios = (annual_returns - risk_free_rate) / annual_volatility\n",
    "\n",
    "# Classify Investment Risk\n",
    "def classify_risk(volatility):\n",
    "    if volatility < 0.3:\n",
    "        return 'Low Risk'\n",
    "    elif 0.3 <= volatility < 0.5:\n",
    "        return 'Moderate Risk'\n",
    "    else:\n",
    "        return 'High Risk'\n",
    "\n",
    "df['investment_status'] = df['stock_symbol'].map(lambda x: classify_risk(annual_volatility[x]))\n",
    "\n",
    "# Update MySQL Database\n",
    "for stock in df['stock_symbol'].unique():\n",
    "    cursor.execute(\"\"\"\n",
    "        UPDATE stock_prices \n",
    "        SET annualized_return = %s, \n",
    "            annualized_volatility = %s, \n",
    "            sharpe_ratio = %s, \n",
    "            investment_status = %s \n",
    "        WHERE stock_symbol = %s\n",
    "    \"\"\", (annual_returns[stock], annual_volatility[stock], sharpe_ratios[stock], classify_risk(annual_volatility[stock]), stock))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\" Data successfully updated in MySQL!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch stock prices in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "#  Connect to MySQL Database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"pass\",  \n",
    "    database=\"db_name\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#  Fetch stock price data\n",
    "query = \"SELECT date, stock_symbol, close_price FROM stock_prices ORDER BY stock_symbol, date;\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "#  Close the connection\n",
    "conn.close()\n",
    "\n",
    "#  Convert 'date' column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "#  Display DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sort DataFrame by stock symbol and date\n",
    "df = df.sort_values(by=['stock_symbol', 'date'])\n",
    "\n",
    "#  Calculate Daily Returns\n",
    "df['daily_return'] = df.groupby('stock_symbol')['close_price'].pct_change()\n",
    "\n",
    "#  Display results\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Annualized Return (Average Daily Return * 252 Trading Days)\n",
    "annual_returns = df.groupby('stock_symbol')['daily_return'].mean() * 252\n",
    "\n",
    "#  Annualized Volatility (Standard Deviation of Daily Return * sqrt(252))\n",
    "annual_volatility = df.groupby('stock_symbol')['daily_return'].std() * (252 ** 0.5)\n",
    "\n",
    "#  Store in a DataFrame\n",
    "portfolio_metrics = pd.DataFrame({\n",
    "    'annualized_return': annual_returns,\n",
    "    'annualized_volatility': annual_volatility\n",
    "})\n",
    "\n",
    "#  Display the results\n",
    "print(portfolio_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define Risk-Free Rate (3.2% or 0.032 in decimal)\n",
    "risk_free_rate = 0.032\n",
    "\n",
    "#  Calculate Sharpe Ratio\n",
    "portfolio_metrics['sharpe_ratio'] = (portfolio_metrics['annualized_return'] - risk_free_rate) / portfolio_metrics['annualized_volatility']\n",
    "\n",
    "#  Display results\n",
    "print(portfolio_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reconnect to MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"pass\",  \n",
    "    database=\"db_name\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#  Store the updated values\n",
    "for stock, row in portfolio_metrics.iterrows():\n",
    "    query = \"\"\"\n",
    "        UPDATE stock_prices \n",
    "        SET annualized_return = %s, annualized_volatility = %s, sharpe_ratio = %s \n",
    "        WHERE stock_symbol = %s;\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (row['annualized_return'], row['annualized_volatility'], row['sharpe_ratio'], stock))\n",
    "\n",
    "#  Commit and close connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\" Sharpe Ratio and financial metrics updated in MySQL database!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expport Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "#  Connect to MySQL Database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"pass\",  \n",
    "    database=\"db_name\"\n",
    ")\n",
    "\n",
    "#  Run Query to Fetch Data\n",
    "query = \"\"\"\n",
    "SELECT stock_symbol, \n",
    "       date, \n",
    "       close_price, \n",
    "       daily_return, \n",
    "       annualized_return, \n",
    "       annualized_volatility, \n",
    "       sharpe_ratio \n",
    "FROM stock_prices\n",
    "ORDER BY stock_symbol, date;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "#  Save as CSV\n",
    "df.to_csv(\"stock_data.csv\", index=False)\n",
    "\n",
    "#  Close Connection\n",
    "conn.close()\n",
    "\n",
    "print(\" Dataset successfully exported as stock_data.csv!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With investment status data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "#  Connect to MySQL Database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"pass\",  \n",
    "    database=\"db_name\"\n",
    ")\n",
    "\n",
    "#  Fetch stock data\n",
    "query = \"\"\"\n",
    "SELECT stock_symbol, \n",
    "       date, \n",
    "       close_price, \n",
    "       daily_return, \n",
    "       annualized_return, \n",
    "       annualized_volatility, \n",
    "       sharpe_ratio \n",
    "FROM stock_prices\n",
    "ORDER BY stock_symbol, date;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "#  Function to Assign Investment Status\n",
    "def classify_risk(volatility):\n",
    "    if volatility < 0.20:\n",
    "        return 'Low Risk'\n",
    "    elif 0.20 <= volatility < 0.40:\n",
    "        return 'Moderate Risk'\n",
    "    else:\n",
    "        return 'High Risk'\n",
    "\n",
    "#  Apply Classification\n",
    "df['investment_status'] = df['annualized_volatility'].apply(classify_risk)\n",
    "\n",
    "#  Save Final Dataset with Investment Status\n",
    "df.to_csv(\"stock_data_with_risk.csv\", index=False)\n",
    "\n",
    "print(\" Investment Status added & dataset exported as stock_data_with_risk.csv!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = pd.read_csv(\"stock_data_with_risk.csv\")\n",
    "print(df_check.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample Monte Carlo Portfolio Allocation (Replace with actual results)\n",
    "optimal_allocation = {\n",
    "    'AAPL': 0.25,  # 25%\n",
    "    'TSLA': 0.20,  # 20%\n",
    "    'GOOGL': 0.30, # 30%\n",
    "    'AMZN': 0.25   # 25%\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "allocation_df = pd.DataFrame(list(optimal_allocation.items()), columns=['stock_symbol', 'portfolio_allocation'])\n",
    "\n",
    "# Convert allocation percentages to string format (for Tableau)\n",
    "allocation_df['portfolio_allocation'] = (allocation_df['portfolio_allocation'] * 100).astype(str) + '%'\n",
    "\n",
    "print(allocation_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load the dataset with Investment Status\n",
    "df = pd.read_csv(\"stock_data_with_risk.csv\")\n",
    "\n",
    "#  Merge dataset with portfolio allocations based on stock_symbol\n",
    "df = df.merge(allocation_df, on=\"stock_symbol\", how=\"left\")\n",
    "\n",
    "#  Fill missing values (if any stocks were not in Monte Carlo results)\n",
    "df['portfolio_allocation'] = df['portfolio_allocation'].fillna(\"0%\")  \n",
    "\n",
    "#  Save the final dataset\n",
    "df.to_csv(\"stock_data_with_risk_and_allocations.csv\", index=False)\n",
    "\n",
    "print(\" Portfolio allocation added! Final dataset exported as stock_data_with_risk_and_allocations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "#  Step 1: Store optimal allocation into a DataFrame\n",
    "optimal_allocation = {\n",
    "    'stock_symbol': ['AAPL', 'AMZN', 'GOOGL', 'MSFT', 'TSLA'],\n",
    "    'portfolio_allocation': [0.247438, 0.009744, 0.195182, 0.108124, 0.439513]\n",
    "}\n",
    "\n",
    "allocation_df = pd.DataFrame(optimal_allocation)\n",
    "\n",
    "#  Convert allocation values to percentage format for readability\n",
    "allocation_df['portfolio_allocation'] = (allocation_df['portfolio_allocation'] * 100).round(2).astype(str) + '%'\n",
    "\n",
    "#  Display the DataFrame\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Optimal Portfolio Allocation\", dataframe=allocation_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Step 2: Load the existing stock dataset\n",
    "df = pd.read_csv(\"stock_data_with_risk.csv\")  # Load the latest dataset\n",
    "\n",
    "#  Merge dataset with portfolio allocations based on stock_symbol\n",
    "df = df.merge(allocation_df, on=\"stock_symbol\", how=\"left\")\n",
    "\n",
    "#  Fill missing values (for stocks not in portfolio allocation)\n",
    "df['portfolio_allocation'] = df['portfolio_allocation'].fillna(\"0%\")\n",
    "\n",
    "#  Save the final dataset\n",
    "df.to_csv(\"stock_data_with_risk_and_allocations.csv\", index=False)\n",
    "\n",
    "print(\" Portfolio allocation added! Final dataset exported as stock_data_with_risk_and_allocations.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
